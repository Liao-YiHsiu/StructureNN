snnet/train.sh --GibbsIter 1000 --error-function per --dnn-depth 1 --dnn-width 200 --early-stop 1.0 ark:data/nn_post//train.ark ark:data/nn_post//train.lab ark:data/nn_post//train.lat ark:data/nn_post//dev.ark ark:data/nn_post//dev.lab ark:data/nn_post//dev.lat data/nn_post//data_nn.model_1000_1_200
copy-int-vector ark:data/nn_post//train.lab ark,t:- 
LOG (copy-int-vector:main():copy-int-vector.cc:83) Copied 3696 vectors of int32.
feat-to-dim ark:data/nn_post//train.ark - 
nnet-initialize /tmp/tmp.GpFehZaPEt/nnet.proto /tmp/tmp.GpFehZaPEt/nnet.init 
VLOG[1] (nnet-initialize:Init():nnet-nnet.cc:373) <NnetProto>
VLOG[1] (nnet-initialize:Init():nnet-nnet.cc:373) <AffineTransform> <InputDim> 4656 <OutputDim> 200 <BiasMean> -2.000000 <BiasRange> 4.000000 <ParamStddev> 0.020505 <MaxNorm> 0.000000
VLOG[1] (nnet-initialize:Init():nnet-nnet.cc:373) <Sigmoid> <InputDim> 200 <OutputDim> 200
VLOG[1] (nnet-initialize:Init():nnet-nnet.cc:373) <AffineTransform> <InputDim> 200 <OutputDim> 2 <BiasMean> 0.000000 <BiasRange> 0.000000 <ParamStddev> 0.348263 <LearnRateCoef> 1.000000 <BiasLearnRateCoef> 0.100000
VLOG[1] (nnet-initialize:Init():nnet-nnet.cc:373) <Softmax> <InputDim> 2 <OutputDim> 2
VLOG[1] (nnet-initialize:Init():nnet-nnet.cc:373) </NnetProto>
LOG (nnet-initialize:main():nnet-initialize.cc:64) Written initialized model to /tmp/tmp.GpFehZaPEt/nnet.init
init-score-path ark:data/nn_post//train.ark ark:/tmp/tmp.GpFehZaPEt/test.ark 
init-score-path ark:data/nn_post//dev.ark ark:/tmp/tmp.GpFehZaPEt/cv.ark 
snnet-train-shuff --learn-rate=0.004 --momentum=0.9 --l1-penalty=0 --l2-penalty=0 --minibatch-size=256 --randomizer-size=32768 --randomize=true --verbose=1 --binary=true --randomizer-seed=777 --negative-num=100 --error-function=per ark:data/nn_post//train.ark ark:data/nn_post//train.lab ark:/tmp/tmp.GpFehZaPEt/test.ark /tmp/tmp.GpFehZaPEt/nnet.init /tmp/tmp.GpFehZaPEt/nnet/nnet.001 
LOG (snnet-train-shuff:Init():nnet-randomizer.cc:31) Seeding by srand with : 777
LOG (snnet-train-shuff:SelectGpuIdAuto():cu-device.cc:262) Selecting from 1 GPUs
LOG (snnet-train-shuff:SelectGpuIdAuto():cu-device.cc:277) cudaSetDevice(0): GeForce GTX 780	free:2210M, used:861M, total:3071M, free/total:0.719627
LOG (snnet-train-shuff:SelectGpuIdAuto():cu-device.cc:310) Selected device: 0 (automatically)
LOG (snnet-train-shuff:FinalizeActiveGpu():cu-device.cc:194) The active GPU is [0]: GeForce GTX 780	free:2196M, used:875M, total:3071M, free/total:0.715069 version 3.5
LOG (snnet-train-shuff:PrintMemoryUsage():cu-device.cc:334) Memory used: 0 bytes.
LOG (snnet-train-shuff:DisableCaching():cu-device.cc:731) Disabling caching of GPU memory.
LOG (snnet-train-shuff:main():snnet-train-shuff.cpp:134) TRAINING STARTED
VLOG[1] (snnet-train-shuff:main():snnet-train-shuff.cpp:253) ### After 0 frames,
VLOG[1] (snnet-train-shuff:main():snnet-train-shuff.cpp:254) ### Forward propagation buffer content :
[0] output of <Input>  ( min 0, max 0.28777, mean 0.000428806, variance 1.84587e-06, skewness 26.516, kurtosis 3855.65 ) 
[1] output of <AffineTransform> ( min -3.95573, max 0.00265361, mean -1.96475, variance 1.3002, skewness -0.035515, kurtosis -1.13517 ) 
[2] output of <Sigmoid> ( min 0.018785, max 0.500663, mean 0.171562, variance 0.0197158, skewness 0.814844, kurtosis -0.533153 ) 
[3] output of <AffineTransform> ( min -0.858822, max -0.154209, mean -0.510512, variance 0.117442, skewness 1.72081e-05, kurtosis -1.99992 ) 
[4] output of <Softmax> ( min 0.332979, max 0.667021, mean 0.5, variance 0.0272055, skewness -2.12816e-08, kurtosis -1.99997 ) 

VLOG[1] (snnet-train-shuff:main():snnet-train-shuff.cpp:256) ### Backward propagation buffer content :
[0] diff of <Input>  ( min -0.0477836, max 0.0512336, mean 8.08419e-05, variance 0.000185487, skewness -0.00236702, kurtosis 0.000923395 ) 
[1] diff-output of <AffineTransform> ( min -0.165294, max 0.209905, mean 0.0012326, variance 0.00217927, skewness 0.544338, kurtosis 3.02157 ) 
[2] diff-output of <Sigmoid> ( min -0.908559, max 0.990371, mean -0.0170393, variance 0.118122, skewness 0.247293, kurtosis -0.0484588 ) 
[3] diff-output of <AffineTransform> ( min -0.666039, max 0.666039, mean -1.92085e-09, variance 0.436951, skewness -8.96789e-09, kurtosis -1.99119 ) 
[4] diff-output of <Softmax> ( min -0.666039, max 0.666039, mean -1.92085e-09, variance 0.436951, skewness -8.96789e-09, kurtosis -1.99119 ) 

VLOG[1] (snnet-train-shuff:main():snnet-train-shuff.cpp:257) ### Gradient stats :
Component 1 : <AffineTransform>, 
  linearity_grad ( min -0.136383, max 0.17294, mean 0.000135308, variance 4.08379e-05, skewness 1.4238, kurtosis 53.6804 ) , lr-coef 1, max-norm 0
  bias_grad ( min -41.2272, max 52.2739, mean 0.315545, variance 137.803, skewness 0.543, kurtosis 2.96768 ) , lr-coef 1
Component 2 : <Sigmoid>, 
Component 3 : <AffineTransform>, 
  linearity_grad ( min -83.0291, max 83.0291, mean -1.09673e-07, variance 1358.07, skewness -1.9315e-08, kurtosis -0.162203 ) , lr-coef 1, max-norm 0
  bias_grad ( min -166.225, max 166.225, mean -7.62939e-06, variance 27630.7, skewness 0, kurtosis -2 ) , lr-coef 0.1
Component 4 : <Softmax>, 

